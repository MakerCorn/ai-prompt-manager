# Instruere - AI Prompt Manager

A comprehensive AI prompt management system with unified architecture supporting both single-user and multi-tenant deployments. Features advanced authentication, real-time token cost estimation, AI-powered prompt optimization, and secure API access.

## ü§ñ Understanding AI Prompts

**What are prompts?** Prompts are instructions you give to AI systems like ChatGPT or Claude. Think of them as questions or commands that tell the AI what you want it to do.

**System Prompts** set the AI's role and behavior. For example: "You are a helpful writing assistant. Always write in a friendly tone." These prompts stay active for the entire conversation.

**User Prompts** are your specific requests. For example: "Write a professional email declining a meeting invitation." These change with each request you make.

**Why good prompts matter:** Clear, specific prompts get better results. Vague prompts like "help me write" often produce unhelpful responses. Detailed prompts like "write a 200-word product description for wireless headphones targeting college students" give you exactly what you need.

**The cost problem:** AI services charge based on how many words (tokens) you use. Longer prompts cost more money. Finding the right balance between detail and brevity saves money while getting good results.

**Why you need prompt management:** If you use AI regularly, you'll create many prompts for different tasks. This application helps you store, organize, improve, and reuse your best prompts. You can also calculate costs, combine prompts for complex tasks, and share prompts with your team.

## üìã Table of Contents

- [ü§ñ Understanding AI Prompts](#-understanding-ai-prompts)
- [üåü Key Features](#-key-features)
- [üöÄ Quick Start](#-quick-start)
- [‚öôÔ∏è Configuration](#Ô∏è-configuration)
- [üåê Multi-Language Support](#-multi-language-support)
- [üßÆ Token Calculator Guide](#-token-calculator-guide)
- [üìù Prompt Management](#-prompt-management)
- [üöÄ Prompt Optimizer Guide](#-prompt-optimizer-guide)
- [üß© Prompt Builder Guide](#-prompt-builder-guide)
- [üîë API Access](#-api-access)
- [üîµ Azure AI & Entra ID Integration](#-azure-ai--entra-id-integration)
- [üè¢ Multi-Tenant Features](#-multi-tenant-features)
- [üöÄ Development](#-development)
- [üîí Production Deployment](#-production-deployment)
- [üöÄ Multi-Language Quick Reference](#-multi-language-quick-reference)
- [üìö Additional Resources](#-additional-resources)
- [üìÑ License](#-license)

## üåü Key Features

### üèóÔ∏è **Unified Architecture**
- **Single Codebase**: Supports both single-user and multi-tenant modes
- **Environment-Based Configuration**: Switch modes via environment variables
- **Backward Compatible**: Existing installations continue working unchanged

### üîê **Security & Authentication**
- **Multi-Tenant Isolation**: Complete data separation between organizations
- **SSO/ADFS Integration**: Enterprise authentication with Microsoft Azure AD
- **Entra ID Support**: Modern Azure Active Directory authentication with Microsoft Graph API integration
- **Role-Based Access**: Admin, User, and Read-only permission levels
- **JWT Session Management**: Secure, stateless authentication tokens
- **API Token System**: Secure programmatic access with expiring tokens

### üßÆ **Advanced AI Features**
- **Token Calculator**: Real-time cost estimation for all major AI models including Azure OpenAI and Azure AI Studio
- **Multi-Service Prompt Optimizer**: AI-powered optimization with LangWatch, PromptPerfect, LangSmith, Helicone support
- **Prompt Builder**: Drag-and-drop interface to combine multiple prompts into new ones
- **Multi-Provider Support**: OpenAI, Claude, Gemini, Azure OpenAI, Azure AI Studio, LM Studio, Ollama, Llama.cpp
- **Enhancement Engine**: Improve prompts using different AI models

### üåê **Modern User Experience**
- **Multi-Language Support**: 10 languages with real-time switching
- **Responsive Design**: Mobile-first, adaptive interface
- **Modern UI Components**: Professional styling with accessibility features
- **Dark Mode Support**: Automatic theme switching
- **Intuitive Navigation**: Simplified, context-aware interface

### üîå **Developer Experience**
- **REST API**: Comprehensive API with interactive documentation
- **Docker Support**: Production-ready containerization
- **Database Flexibility**: SQLite for development, PostgreSQL for production
- **Comprehensive Testing**: Full test suite with isolation verification

---

## üöÄ Quick Start

### Prerequisites
- Python 3.12+
- Poetry (recommended) or pip
- Optional: PostgreSQL for production

### Installation

1. **Clone and Setup**
```bash
git clone <repository-url>
cd ai-prompt-manager
poetry install

# Copy and customize configuration
cp .env.example .env
# Edit .env file for your specific setup
```

2. **Launch Application**
```bash
# Universal launcher with smart defaults (recommended)
poetry run python run.py

# Command line mode selection
poetry run python run.py --single-user     # Single-user mode
poetry run python run.py --with-api        # Multi-tenant + API
poetry run python run.py --single-user --with-api  # Single-user + API

# Custom server configuration
poetry run python run.py --port 8080 --host 127.0.0.1
python run.py --help  # See all options
```

3. **Access Application**
- Open browser to `http://localhost:7860`
- Login with: `admin@localhost` / `admin123` (multi-tenant)

### Docker Deployment
```bash
# Quick start with latest release
docker run -p 7860:7860 ghcr.io/makercorn/ai-prompt-manager:latest

# Specific version
docker run -p 7860:7860 ghcr.io/makercorn/ai-prompt-manager:v1.0.0

# Production with PostgreSQL
docker-compose -f docker-compose.prod.yml up -d

# Development
docker-compose up -d
```

---

## ‚öôÔ∏è Configuration

### Application Modes

The unified AI Prompt Manager supports multiple deployment modes controlled by environment variables:

#### Environment Variables

Create a `.env` file or set these environment variables:

```bash
# Application Mode
MULTITENANT_MODE=true          # Enable multi-tenant mode (default: true)
ENABLE_API=false               # Enable REST API endpoints (default: false)

# Server Configuration  
SERVER_HOST=0.0.0.0           # Server host (default: 0.0.0.0)
SERVER_PORT=7860              # Server port (default: 7860)

# Database Configuration
DB_TYPE=sqlite                # Database type: sqlite or postgres (default: sqlite)
DB_PATH=prompts.db           # SQLite database path (default: prompts.db)
POSTGRES_DSN=postgresql://... # PostgreSQL connection string (if using postgres)

# Development
DEBUG=false                   # Enable debug mode (default: false)
LOCAL_DEV_MODE=true          # Enable local development features (default: false)
```

#### Mode Combinations

1. **Single-User Mode** (Legacy compatibility)
   ```bash
   MULTITENANT_MODE=false
   ENABLE_API=false
   ```

2. **Multi-Tenant Mode** (Recommended)
   ```bash
   MULTITENANT_MODE=true
   ENABLE_API=false
   ```

3. **Multi-Tenant with API** (Full featured)
   ```bash
   MULTITENANT_MODE=true
   ENABLE_API=true
   ```

### Quick Mode Examples

**Using Command Line Arguments:**
```bash
# Single-user mode (no authentication)
python run.py --single-user

# Multi-tenant mode with API
python run.py --with-api

# Single-user mode with API
python run.py --single-user --with-api

# Custom server settings
python run.py --port 8080 --host 127.0.0.1

# Debug mode with public sharing
python run.py --debug --share
```

**Using Environment Variables:**
```bash
# Single-user mode
MULTITENANT_MODE=false python run.py

# Multi-tenant with API
ENABLE_API=true python run.py

# Production mode with PostgreSQL
DB_TYPE=postgres POSTGRES_DSN="postgresql://user:pass@localhost/prompts" python run.py

# Full configuration
MULTITENANT_MODE=true ENABLE_API=true SERVER_PORT=8080 DEBUG=false python run.py
```

---

## üåê Multi-Language Support

AI Prompt Manager supports **10 languages** with real-time interface switching, making it accessible to users worldwide. The internationalization system provides comprehensive translations for all UI elements.

### üåç Supported Languages

| Language | Code | Native Name | Status |
|----------|------|-------------|--------|
| **English** | `en` | English | ‚úÖ Complete |
| **Spanish** | `es` | Espa√±ol | ‚úÖ Complete |
| **French** | `fr` | Fran√ßais | ‚úÖ Complete |
| **German** | `de` | Deutsch | ‚úÖ Complete |
| **Chinese** | `zh` | ‰∏≠Êñá | ‚úÖ Complete |
| **Japanese** | `ja` | Êó•Êú¨Ë™û | ‚úÖ Complete |
| **Portuguese** | `pt` | Portugu√™s | ‚úÖ Complete |
| **Russian** | `ru` | –†—É—Å—Å–∫–∏–π | ‚úÖ Complete |
| **Arabic** | `ar` | ÿßŸÑÿπÿ±ÿ®Ÿäÿ© | ‚úÖ Complete |
| **Hindi** | `hi` | ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä | ‚úÖ Complete |

### üîÑ How to Change Language

#### **Method 1: Using the Interface (Recommended)**
1. **Locate the Language Selector**: Look for the üåê Language dropdown in the top-right corner
2. **Select Your Language**: Click the dropdown and choose your preferred language
3. **Instant Update**: The interface will immediately switch to the selected language

#### **Method 2: Environment Configuration**
Set the default language for new sessions:

```bash
# Set default language (optional)
DEFAULT_LANGUAGE=es python run.py  # Spanish
DEFAULT_LANGUAGE=fr python run.py  # French
DEFAULT_LANGUAGE=zh python run.py  # Chinese
```

#### **Method 3: URL Parameter**
Access the interface with a specific language:

```bash
# Examples
http://localhost:7860/?lang=es  # Spanish
http://localhost:7860/?lang=fr  # French
http://localhost:7860/?lang=zh  # Chinese
```

### üéØ What Gets Translated

The multi-language system covers **all user-facing elements**:

#### **Interface Elements**
- ‚úÖ Navigation menus and tabs
- ‚úÖ Button labels and actions
- ‚úÖ Form fields and placeholders
- ‚úÖ Status messages and notifications
- ‚úÖ Help text and tooltips

#### **Application Sections**
- ‚úÖ **Authentication**: Login forms, SSO options
- ‚úÖ **Prompt Management**: Add, edit, delete prompts
- ‚úÖ **Library**: Search, categories, filters
- ‚úÖ **Token Calculator**: Model selection, cost estimation
- ‚úÖ **API Management**: Token creation, documentation
- ‚úÖ **Settings**: Configuration options
- ‚úÖ **Admin Panel**: User and tenant management

#### **AI Features**
- ‚úÖ **LangWatch Integration**: Optimization interface
- ‚úÖ **Enhancement Engine**: Prompt improvement tools
- ‚úÖ **Error Messages**: Validation and system feedback

### üåê Translation Feature

When using the interface in a non-English language, AI Prompt Manager provides an automatic **translation feature** to help you work with AI enhancement tools that work best with English prompts.

#### **How Translation Works**

1. **Automatic Detection**: Translation button appears automatically when UI language is not English
2. **One-Click Translation**: Click "Translate to English" button in prompt editor
3. **Smart Replacement**: Translated text replaces original content in the editor
4. **Validation**: Translated text undergoes validation before saving
5. **Status Feedback**: Clear success/error messages guide the process

#### **Supported Translation Services**

| Service | Quality | Setup | Cost |
|---------|---------|-------|------|
| **OpenAI** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | API Key | Paid |
| **Google Translate** | ‚≠ê‚≠ê‚≠ê‚≠ê | API Key | Paid |
| **LibreTranslate** | ‚≠ê‚≠ê‚≠ê | Optional Key | Free/Paid |
| **Mock** | ‚≠ê | None | Free |

#### **Configuration**

Set up translation services via environment variables:

```bash
# Use OpenAI for highest quality
TRANSLATION_SERVICE=openai
OPENAI_API_KEY=your_openai_api_key

# Use Google Translate  
TRANSLATION_SERVICE=google
GOOGLE_TRANSLATE_API_KEY=your_google_key

# Use LibreTranslate (open source)
TRANSLATION_SERVICE=libre
LIBRETRANSLATE_URL=https://libretranslate.de/translate
LIBRETRANSLATE_API_KEY=optional_key

# Use mock for testing (default)
TRANSLATION_SERVICE=mock
```

#### **Usage Workflow**

1. **Switch Language**: Change UI to your preferred language (Spanish, French, etc.)
2. **Write Prompt**: Enter your prompt in your native language
3. **Translate**: Click the "üåê Translate to English" button that appears
4. **Enhance**: Use the translated English text with AI enhancement tools
5. **Save**: Save the improved prompt after validation

#### **Example**

```text
Original (Spanish): "Escribe un poema sobre la naturaleza"
Translated (English): "Write a poem about nature"  
Enhanced (English): "Create a beautiful, evocative poem about the wonders 
                     of nature, focusing on vivid imagery and emotional depth"
```

### üîß Advanced Configuration

#### **Programmatic Language Control**
Access the internationalization system programmatically:

```python
from i18n import i18n, t

# Get available languages
languages = i18n.get_available_languages()
print(languages)  # {'en': 'English', 'es': 'Espa√±ol', ...}

# Change language
i18n.set_language('es')

# Translate text
title = t('app.title')  # Returns translated app title
welcome = t('auth.welcome', name='John')  # With parameters
```

#### **Custom Translations**
Extend translations for custom deployments:

```python
# Add custom translations
from i18n import i18n

# Add new language or extend existing
custom_translations = {
    'custom.message': 'My custom message',
    'custom.button': 'Custom Button'
}

# Extend existing language
i18n.translations['en'].update(custom_translations)
```

### üåü Language Features

#### **Smart Fallbacks**
- **Automatic Fallback**: Missing translations default to English
- **Graceful Degradation**: Untranslated keys display as readable text
- **Context Preservation**: Formatting and parameters work across all languages

#### **Cultural Considerations**
- **Text Direction**: Right-to-left support for Arabic
- **Number Formatting**: Locale-appropriate number display
- **Date Formats**: Regional date and time formatting
- **Currency**: Localized cost estimates in token calculator

#### **Accessibility**
- **Screen Readers**: Proper language attributes for assistive technology
- **Keyboard Navigation**: Language switching via keyboard shortcuts
- **High Contrast**: Language selector works with accessibility themes

### üé® UI Adaptations

The interface automatically adapts to different languages:

#### **Layout Flexibility**
- **Dynamic Text Sizing**: Accommodates longer/shorter translations
- **Responsive Labels**: Forms adjust to text length variations
- **Icon Consistency**: Universal icons complement text labels

#### **Typography**
- **Font Support**: Web fonts that support all character sets
- **Readability**: Optimized contrast and spacing for each language
- **Consistency**: Unified styling across all language versions

### üîç Technical Details

#### **Translation Architecture**
- **Embedded Translations**: No external files required for reliability
- **Key-Based System**: Hierarchical translation keys (e.g., `auth.login`)
- **Parameter Support**: Dynamic content with variable substitution
- **Caching**: Efficient translation loading and memory usage

#### **File Structure**
```
ai-prompt-manager/
‚îú‚îÄ‚îÄ i18n.py                 # Internationalization system
‚îú‚îÄ‚îÄ ui_components.py        # Language-aware UI components
‚îî‚îÄ‚îÄ prompt_manager.py       # Main interface with i18n integration
```

#### **Browser Support**
- **Modern Browsers**: Full support in Chrome, Firefox, Safari, Edge
- **Fallback Support**: Graceful degradation in older browsers
- **Mobile Optimized**: Touch-friendly language switching on mobile devices

### ‚ùì Troubleshooting

#### **Common Issues**

**Language not switching immediately:**
- Refresh the page or restart the interface
- Check browser console for JavaScript errors

**Missing translations:**
- Some text remains in English - this is expected fallback behavior
- Report missing translations via GitHub issues

**Performance with many languages:**
- All translations are loaded efficiently in memory
- No performance impact from multiple language support

#### **Getting Help**
- üìñ **Documentation**: Check this guide for configuration details
- üêõ **Bug Reports**: Report translation issues on GitHub
- üí° **Feature Requests**: Suggest new languages or improvements
- üåç **Community**: Join discussions about localization

---

## üßÆ Token Calculator Guide

### What are Tokens?

**Tokens** are the basic units that AI models use to process text. Understanding tokens is crucial for:
- **Cost Control**: AI services charge based on token usage
- **Performance**: More tokens = longer processing time
- **Limits**: Models have maximum token limits per request

### How Tokenization Works

- **Words aren't tokens**: "Hello world" = 2 tokens, but "artificial intelligence" = 4 tokens
- **Subwords**: Long words are split (e.g., "understanding" = 2-3 tokens)
- **Special characters**: Punctuation and symbols count as tokens
- **Languages vary**: Non-English text may use more tokens

### Using the Token Calculator

#### 1. **Access the Calculator**
- Navigate to **Prompt Management** tab after logging in
- Find the **üßÆ Token Calculator** section below the prompt content area

#### 2. **Calculate Token Costs**

1. **Enter your prompt** in the "Prompt Content" field
2. **Select target AI model** from the dropdown:
   - `gpt-4` - Most accurate, higher cost
   - `gpt-3.5-turbo` - Fast and economical
   - `claude-3-opus` - High-quality reasoning
   - `gemini-pro` - Google's model
3. **Set max completion tokens** - Expected response length (500-2000 typical)
4. **Click "üßÆ Calculate Tokens"**

#### 3. **Understanding Results**

The calculator provides:
```
üßÆ Token Estimate for gpt-4

üìù Prompt Tokens: 45        ‚Üê Your input text
üí¨ Max Completion Tokens: 1,000  ‚Üê Expected response
üìä Total Tokens: 1,045     ‚Üê Combined usage
‚öôÔ∏è Tokenizer: gpt-4        ‚Üê Method used

üí∞ Estimated Cost: $0.0615 USD
   ‚Ä¢ Input: $0.0014         ‚Üê Cost for your prompt
   ‚Ä¢ Output: $0.0600        ‚Üê Cost for AI response

‚ö†Ô∏è Suggestions:
   ‚Ä¢ Large prompt may be expensive
   ‚Ä¢ Consider breaking into smaller prompts
```

#### 4. **Cost Optimization Tips**

**Reduce Costs:**
- ‚úÖ Use shorter, more focused prompts
- ‚úÖ Choose appropriate models (GPT-3.5 for simple tasks)
- ‚úÖ Set reasonable completion token limits
- ‚úÖ Remove repetitive content

**Performance Tips:**
- ‚ö° Shorter prompts = faster responses
- ‚ö° Fewer tokens = less processing time
- ‚ö° Structure prompts clearly for better results

#### 5. **Model Comparison**

| Model | Best For | Cost | Speed | Quality |
|-------|----------|------|-------|---------|
| `gpt-4` | Complex reasoning, code | $$$ | Slower | Highest |
| `gpt-3.5-turbo` | General tasks, chat | $ | Fast | Good |
| `claude-3-opus` | Analysis, writing | $$$ | Moderate | Excellent |
| `claude-3-haiku` | Simple tasks | $ | Fast | Good |
| `gemini-pro` | Multimodal, research | $$ | Moderate | Very Good |

### Token Calculator Features

- **Real-time Estimation**: Instant cost calculation as you type
- **Multi-Model Support**: Accurate tokenization for all major AI providers
- **Cost Breakdown**: Separate input/output cost analysis
- **Optimization Suggestions**: Automatic recommendations for efficiency
- **Complexity Analysis**: Detects repetitive or overly long content

---

## üìù Prompt Management

### Creating Prompts

1. **Navigate to Prompt Management** tab
2. **Fill in prompt details:**
   - **Name**: Unique identifier (required)
   - **Title**: Descriptive title
   - **Category**: Organization (e.g., "Writing", "Analysis")
   - **Content**: Your AI prompt text
   - **Tags**: Comma-separated keywords

3. **Estimate costs** using the Token Calculator
4. **Optimize if needed** with the Prompt Optimizer (see [üöÄ Prompt Optimizer Guide](#-prompt-optimizer-guide))
5. **Save prompt** with "‚ûï Add Prompt"

### Prompt Optimization

Improve your prompts with AI-powered suggestions using multiple optimization services:

1. **Add optimization context** - Describe your prompt's purpose
2. **Select target model** - Choose your intended AI model
3. **Click "üöÄ Optimize"** - Uses your configured optimization service
4. **Review suggestions** - See score, reasoning, and improvements
5. **Accept, retry, or reject** - Choose the best version

For detailed optimization features and configuration, see the [üöÄ Prompt Optimizer Guide](#-prompt-optimizer-guide).

### Prompt Library

- **Browse all prompts** in organized tree view
- **Search by keywords** - Name, title, content, or tags
- **Filter by category** - Organize by type or purpose
- **Quick actions** - Load, edit, or delete prompts

---

## üöÄ Prompt Optimizer Guide

The **Prompt Optimizer** is an AI-powered system that analyzes and improves your prompts automatically, making them more effective, clear, and targeted for better AI model performance. The system supports multiple optimization services and provides detailed feedback to help you create superior prompts.

### üéØ What is Prompt Optimization?

Prompt optimization uses AI to analyze your prompts and suggest improvements based on:
- **Clarity**: Making instructions more specific and unambiguous
- **Effectiveness**: Improving response quality and accuracy  
- **Structure**: Adding organization and logical flow
- **Specificity**: Replacing vague terms with concrete directions
- **Context**: Providing appropriate background information

### üîß How to Use the Prompt Optimizer

#### 1. **Access the Optimizer**
- Navigate to **Prompt Management** tab
- Create or edit a prompt in the content area
- Find the **üöÄ Prompt Optimizer** section below the prompt editor

#### 2. **Configure Optimization Settings**
- **Optimization Context**: Describe your prompt's purpose (optional but recommended)
- **Target AI Model**: Select your intended model (GPT-4, Claude, etc.)
- **Optimization Goals**: Choose what to improve (clarity, specificity, effectiveness)

#### 3. **Run Optimization**
- Click **üöÄ Optimize with LangWatch** (or your configured service)
- Wait for analysis - typically takes 5-15 seconds
- Review the optimization results

#### 4. **Review Results**
The optimizer provides:
```
üöÄ Optimization Results

üìä Optimization Score: 78.5/100
üéØ Improvement: +23.5 points

‚ú® Optimized Prompt:
[Your improved prompt text here with better structure and clarity]

üí° Key Improvements:
‚Ä¢ Added role definition for better responses
‚Ä¢ Structured approach for better organization  
‚Ä¢ Added output formatting instructions
‚Ä¢ Enhanced specificity for clearer results

üß† Reasoning:
The optimization expanded the prompt with additional context, 
defined the AI's role for better responses, and added structural 
elements for clarity to enhance effectiveness and clarity.
```

#### 5. **Accept or Iterate**
- **Accept**: Replace your original prompt with the optimized version
- **Retry**: Run optimization again with different settings
- **Reject**: Keep your original prompt
- **Manual Edit**: Use suggestions to manually improve your prompt

### üõ†Ô∏è Optimization Services

AI Prompt Manager supports multiple optimization backends for flexibility and reliability:

#### **üöÄ LangWatch** (Recommended)
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Enterprise-grade optimization
- **Features**: Advanced analytics, A/B testing, real-time monitoring
- **Best For**: Production applications, complex prompts
- **Setup**: Requires API key and project ID

#### **üîç PromptPerfect**
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê Specialized prompt refinement
- **Features**: Multi-model optimization, instant feedback
- **Best For**: Creative prompts, image generation
- **Setup**: API key required

#### **üß† LangSmith**
- **Quality**: ‚≠ê‚≠ê‚≠ê‚≠ê LangChain ecosystem integration
- **Features**: Version control, collaborative editing, testing
- **Best For**: LangChain applications, team workflows
- **Setup**: LangSmith account and API key

#### **‚ö° Helicone**
- **Quality**: ‚≠ê‚≠ê‚≠ê Observability-focused optimization
- **Features**: Performance monitoring, cost tracking
- **Best For**: Production monitoring, debugging
- **Setup**: Helicone account and API key

#### **üß™ Built-in Optimizer** (Default)
- **Quality**: ‚≠ê‚≠ê‚≠ê Rule-based improvements
- **Features**: No external dependencies, instant results
- **Best For**: Development, testing, offline use
- **Setup**: No configuration required

### üîß Configuration

Configure your preferred optimization service via environment variables:

#### **LangWatch Configuration**
```bash
# LangWatch (Recommended for production)
PROMPT_OPTIMIZER=langwatch
LANGWATCH_API_KEY=your_langwatch_api_key
LANGWATCH_PROJECT_ID=your_project_id
LANGWATCH_ENDPOINT=https://api.langwatch.ai  # Optional
```

#### **PromptPerfect Configuration**
```bash
# PromptPerfect
PROMPT_OPTIMIZER=promptperfect
PROMPTPERFECT_API_KEY=your_promptperfect_api_key
```

#### **LangSmith Configuration**
```bash
# LangSmith (LangChain)
PROMPT_OPTIMIZER=langsmith
LANGSMITH_API_KEY=your_langsmith_api_key
LANGSMITH_PROJECT=your_project_name
```

#### **Helicone Configuration**
```bash
# Helicone
PROMPT_OPTIMIZER=helicone
HELICONE_API_KEY=your_helicone_api_key
HELICONE_APP_NAME=ai-prompt-manager
```

#### **Built-in Optimizer (Default)**
```bash
# Built-in optimizer (no external service required)
PROMPT_OPTIMIZER=builtin
# No additional configuration needed
```

### üìä Optimization Features

#### **Smart Analysis**
- **Prompt Length Analysis**: Identifies overly long or short prompts
- **Complexity Detection**: Recognizes overly complex or repetitive content
- **Structure Assessment**: Evaluates logical flow and organization
- **Clarity Metrics**: Measures instruction specificity and precision

#### **Multi-Model Support**
The optimizer adapts suggestions based on your target AI model:
- **GPT-4**: Focus on complex reasoning and detailed instructions
- **GPT-3.5-turbo**: Emphasize clarity and conciseness
- **Claude**: Optimize for conversational flow and context
- **Gemini**: Balance creativity with structure

#### **Optimization Goals**
Customize optimization focus:
- **Clarity**: Remove ambiguity, add specific instructions
- **Effectiveness**: Improve response quality and accuracy
- **Conciseness**: Remove redundancy while maintaining completeness
- **Structure**: Add organization and logical flow
- **Creativity**: Enhance creative and open-ended prompts

### üéØ Best Practices

#### **Writing Prompts for Optimization**
1. **Provide Context**: Add background information about your use case
2. **Be Specific**: Include details about desired output format
3. **Set Clear Goals**: Define what you want the AI to accomplish
4. **Use Examples**: Include sample inputs/outputs when relevant

#### **Optimization Workflow**
```
Original Prompt ‚Üí Configure Settings ‚Üí Run Optimizer ‚Üí Review Results ‚Üí Test ‚Üí Deploy
```

#### **Iterative Improvement**
- Start with basic prompts and optimize iteratively
- Test optimized prompts with real use cases
- Use A/B testing to compare versions
- Track performance metrics over time

### üîç Advanced Features

#### **Batch Optimization**
Optimize multiple prompts simultaneously:
```bash
# Coming soon: Batch optimization API
POST /api/optimize/batch
{
  "prompts": ["prompt1", "prompt2", "prompt3"],
  "settings": { "target_model": "gpt-4", "goals": ["clarity", "effectiveness"] }
}
```

#### **Custom Optimization Rules**
Define organization-specific optimization patterns:
```python
# Custom optimization rules (advanced)
custom_rules = {
    "add_role_definition": True,
    "require_output_format": True, 
    "max_length": 2000,
    "industry_context": "healthcare"
}
```

#### **Optimization History**
Track improvement over time:
- View optimization history for each prompt
- Compare versions and see improvement metrics
- Export optimization reports for analysis

### üìà Performance Metrics

#### **Optimization Score Breakdown**
- **0-30**: Poor - Requires significant improvement
- **30-60**: Fair - Some optimization needed  
- **60-80**: Good - Well-structured prompt
- **80-95**: Excellent - Highly optimized prompt
- **95-100**: Perfect - No improvements needed

#### **Improvement Categories**
- **+5-10 points**: Minor improvements (formatting, clarity)
- **+10-20 points**: Moderate improvements (structure, specificity)  
- **+20-30 points**: Major improvements (complete restructuring)
- **+30+ points**: Significant transformation (role definition, context)

### üåê Multi-Language Support

The prompt optimizer works seamlessly with the translation system:

1. **Translate First**: Use "üåê Translate to English" for non-English prompts
2. **Optimize**: Run optimization on English text for best results
3. **Translate Back**: Optionally translate optimized prompt back to original language

### üß™ Testing the Optimizer

You can test the prompt optimization system using the included test script:

```bash
# Test with built-in optimizer (no API keys required)
python test_langwatch_integration.py

# Test with specific service (set environment variables first)
PROMPT_OPTIMIZER=langwatch LANGWATCH_API_KEY=your_key python test_langwatch_integration.py

# Test service switching
PROMPT_OPTIMIZER=promptperfect PROMPTPERFECT_API_KEY=your_key python test_langwatch_integration.py
```

The test script will:
- ‚úÖ Check service availability and configuration
- ‚úÖ Test simple and complex prompt optimization
- ‚úÖ Verify error handling for edge cases
- ‚úÖ Test different optimization goals
- ‚úÖ Show before/after comparisons and scoring

### üö® Troubleshooting

#### **Common Issues**

**Optimization Not Working:**
- Check API key configuration in environment variables
- Verify internet connectivity for external services
- Try built-in optimizer as fallback

**Poor Optimization Results:**
- Provide more context about prompt purpose
- Try different optimization goals
- Use multiple optimization services for comparison

**Service Unavailable:**
- Built-in optimizer always available as backup
- Check service status pages for external providers
- Configure multiple services for redundancy

#### **Error Messages**
- `API_KEY_MISSING`: Set required environment variables
- `SERVICE_UNAVAILABLE`: External service is down, use alternative
- `PROMPT_TOO_LONG`: Shorten prompt or split into multiple parts
- `RATE_LIMIT_EXCEEDED`: Wait and retry, or upgrade service plan

### üéì Examples

#### **Example 1: Basic Prompt Optimization**
```
Original: "Write about dogs"

Optimized: "You are a knowledgeable pet expert. Write a comprehensive 
guide about dogs that covers the following topics:

1. Popular dog breeds and their characteristics
2. Basic care requirements (feeding, exercise, grooming)
3. Training tips for new dog owners
4. Health considerations and veterinary care

Please structure your response with clear headings and provide 
practical, actionable advice for both new and experienced dog owners."

Improvement: +45 points (clarity, structure, specificity)
```

#### **Example 2: Technical Prompt Optimization**
```
Original: "Explain API design"

Optimized: "You are a senior software architect with expertise in 
API design. Explain REST API design best practices for a junior 
developer, covering:

Step 1: Core principles (statelessness, resource-based URLs)
Step 2: HTTP methods and status codes usage
Step 3: Authentication and security considerations  
Step 4: Documentation and versioning strategies

Provide concrete examples for each concept and explain common 
pitfalls to avoid. Format your response as a structured tutorial 
with code examples where appropriate."

Improvement: +38 points (role definition, structure, examples)
```

### üîó Integration with Other Features

#### **Token Calculator Integration**
- Optimization results show token impact
- Compare costs before/after optimization
- Optimize for specific token budgets

#### **Prompt Builder Integration** 
- Optimize combined prompts after building
- Apply optimization to individual components
- Create optimized prompt templates

#### **API Integration**
```bash
# Optimize via API
POST /api/prompts/optimize
{
  "content": "your prompt here",
  "context": "analysis task",
  "target_model": "gpt-4",
  "goals": ["clarity", "effectiveness"]
}
```

---

## üß© Prompt Builder Guide

The **Prompt Builder** is a powerful drag-and-drop interface that allows you to combine multiple existing prompts into sophisticated new ones. Perfect for creating complex, multi-layered prompts from your existing prompt library.

### üéØ What is the Prompt Builder?

The Prompt Builder enables you to:
- **Combine Multiple Prompts**: Merge 2 or more existing prompts into a single, comprehensive prompt
- **Use Smart Templates**: Choose from 4 different combination methods
- **Drag-and-Drop Interface**: Intuitive, visual prompt selection and organization  
- **Live Preview**: See exactly how your combined prompt will look before saving
- **Seamless Integration**: Open combined prompts directly in the main editor for further refinement

### üöÄ Getting Started

#### 1. **Access the Prompt Builder**
- Navigate to the **üß© Prompt Builder** tab in the main interface
- Ensure you have some existing prompts created (minimum 2 prompts required)

#### 2. **Basic Workflow**
```
Available Prompts ‚Üí Select & Combine ‚Üí Choose Template ‚Üí Preview ‚Üí Edit
```

### üìã Step-by-Step Guide

#### **Step 1: Browse Available Prompts**
- The **Available Prompts** panel shows all your existing prompts as cards
- Each card displays:
  - **Prompt name** and category
  - **Preview** of the content
  - **Character count** and type (regular or enhancement)
  - **Visual indicators** for prompt types

#### **Step 2: Select Prompts to Combine**
- **Drag prompts** from the Available section to the Selected area
- **Alternative**: Click prompts to add them to your selection
- **Reorder**: Drag selected prompts to change their order
- **Remove**: Drag prompts out of the selected area to remove them

#### **Step 3: Choose a Combination Template**

| Template | Icon | Description | Best For |
|----------|------|-------------|----------|
| **Sequential** | üìã | Combines prompts one after another with clear separation | Simple prompt chaining |
| **Sections** | üìë | Creates distinct sections with headers for each prompt | Structured, multi-part prompts |
| **Layered** | üèóÔ∏è | Builds context in layers with base + additional layers | Complex context building |
| **Custom** | üé® | Uses your own formatting template with placeholders | Advanced customization |

#### **Step 4: Customize Options**
- **Custom Separator**: Choose how prompts are separated (default: `\n\n`)
- **Add Numbers**: Automatically number each prompt section
- **Template-Specific Options**: Additional settings based on selected template

#### **Step 5: Preview Your Creation**
- The **Preview** panel shows exactly how your combined prompt will look
- **Real-time updates** as you change templates or options
- **Character count** and **source prompt tracking**

#### **Step 6: Finalize and Edit**
- Click **üîó Combine Prompts** to generate the final result
- Click **üìù Open in Editor** to transfer the combined prompt to the main editor
- **Continue editing** in the main interface with full editing capabilities

### üé® Template Details

#### **üìã Sequential Template**
Combines prompts in order with simple separation:
```
1. First prompt content here

2. Second prompt content here

3. Third prompt content here
```

**Options:**
- ‚úÖ Add sequence numbers
- ‚úÖ Custom separator between prompts

#### **üìë Sections Template**  
Creates clearly defined sections with headers:
```
## First Prompt Title
First prompt content here

---

## Second Prompt Title  
Second prompt content here

---

## Third Prompt Title
Third prompt content here
```

**Best for:**
- Multi-part instructions
- Structured analysis prompts
- Documentation generation

#### **üèóÔ∏è Layered Template**
Builds context progressively:
```
Base Context:
Your foundational prompt here

Layer 1:
Additional context or instructions

Layer 2:
Further refinements or specifications

Instructions: Integrate all layers above into a cohesive response.
```

**Best for:**
- Complex reasoning tasks
- Context-heavy prompts
- Graduated instruction sets

#### **üé® Custom Template**
Use your own formatting with placeholders:
```
Template: "Context: {content}\nSource: {name}\nCategory: {category}"
```

**Available Placeholders:**
- `{content}` - The prompt content
- `{name}` - Prompt name
- `{title}` - Prompt title
- `{category}` - Prompt category
- `{tags}` - Prompt tags

### ‚ö° Advanced Features

#### **Smart Metadata Generation**
When you combine prompts, the system automatically generates:
- **Suggested Name**: `Combined_PromptA+PromptB` or `Combined_3_Prompts_20250108`
- **Suggested Title**: Based on prompt categories and content
- **Combined Category**: `Combined` or inherited from source prompts
- **Merged Tags**: All unique tags from source prompts plus `combined` and `X-part` tags

#### **Validation and Error Prevention**
- **Minimum Requirements**: Must select at least 2 prompts
- **Duplicate Detection**: Prevents selecting the same prompt twice
- **Length Limits**: Warns if combined prompt exceeds 50,000 characters
- **Template Validation**: Ensures template compatibility with selected prompts

#### **Search and Filter**
- **Search Bar**: Find prompts by name, title, or content
- **Category Filter**: Show only prompts from specific categories
- **Refresh**: Update available prompts after creating new ones

### üåê Multi-Language Support

The Prompt Builder is fully localized in all 10 supported languages:

| Language | Prompt Builder | Available Prompts | Template Options |
|----------|---------------|-------------------|------------------|
| üá∫üá∏ English | Prompt Builder | Available Prompts | Sequential, Sections, Layered, Custom |
| üá™üá∏ Spanish | Constructor de Prompts | Prompts Disponibles | Secuencial, Secciones, Por Capas, Personalizado |
| üá´üá∑ French | Constructeur de Prompts | Prompts Disponibles | S√©quentiel, Sections, En Couches, Personnalis√© |
| üá©üá™ German | Prompt-Builder | Verf√ºgbare Prompts | Sequenziell, Abschnitte, Geschichtet, Benutzerdefiniert |
| üá®üá≥ Chinese | ÊèêÁ§∫ÊûÑÂª∫Âô® | ÂèØÁî®ÊèêÁ§∫ | È°∫Â∫è, ÂàÜÊÆµ, ÂàÜÂ±Ç, Ëá™ÂÆö‰πâ |
| üáØüáµ Japanese | „Éó„É≠„É≥„Éó„Éà„Éì„É´„ÉÄ„Éº | Âà©Áî®ÂèØËÉΩ„Å™„Éó„É≠„É≥„Éó„Éà | È†ÜÊ¨°, „Çª„ÇØ„Ç∑„Éß„É≥, ÈöéÂ±§, „Ç´„Çπ„Çø„É† |
| üáµüáπ Portuguese | Construtor de Prompts | Prompts Dispon√≠veis | Sequencial, Se√ß√µes, Em Camadas, Personalizado |
| üá∑üá∫ Russian | –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –ü—Ä–æ–º–ø—Ç–æ–≤ | –î–æ—Å—Ç—É–ø–Ω—ã–µ –ü—Ä–æ–º–ø—Ç—ã | –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π, –°–µ–∫—Ü–∏–∏, –°–ª–æ–∏—Å—Ç—ã–π, –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π |
| üá∏üá¶ Arabic | ŸÖŸÜÿ¥ÿ¶ ÿßŸÑŸÖÿ∑ÿßŸÑÿ®ÿßÿ™ | ÿßŸÑŸÖÿ∑ÿßŸÑÿ®ÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© | ÿ™ÿ≥ŸÑÿ≥ŸÑŸä, ÿ£ŸÇÿ≥ÿßŸÖ, ÿ∑ÿ®ŸÇÿßÿ™, ŸÖÿÆÿµÿµ |
| üáÆüá≥ Hindi | ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü ‡§¨‡§ø‡§≤‡•ç‡§°‡§∞ | ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§™‡•ç‡§∞‡•â‡§Æ‡•ç‡§™‡•ç‡§ü‡•ç‡§∏ | ‡§ï‡•ç‡§∞‡§Æ‡§ø‡§ï, ‡§ñ‡§Ç‡§°, ‡§™‡§∞‡§§‡§¶‡§æ‡§∞, ‡§ï‡§∏‡•ç‡§ü‡§Æ |

### üí° Use Cases and Examples

#### **Example 1: Content Creation Workflow**
1. **Select prompts**: "Blog Introduction", "SEO Keywords", "Call to Action"
2. **Template**: Sections
3. **Result**: Complete blog post structure with intro, SEO-optimized content, and CTA

#### **Example 2: Analysis Framework**
1. **Select prompts**: "Context Analysis", "SWOT Framework", "Recommendations"
2. **Template**: Layered
3. **Result**: Comprehensive analysis prompt with progressive depth

#### **Example 3: Creative Writing**
1. **Select prompts**: "Character Development", "Setting Description", "Plot Points"
2. **Template**: Sequential
3. **Result**: Complete creative writing framework

#### **Example 4: Technical Documentation**
1. **Select prompts**: "Requirements Gathering", "Technical Specs", "User Stories"
2. **Template**: Sections with custom separator
3. **Result**: Structured technical documentation prompt

### üîß Tips and Best Practices

#### **Prompt Selection Tips**
- ‚úÖ **Start with complementary prompts** that work well together
- ‚úÖ **Consider prompt length** - very long prompts may overwhelm the combination
- ‚úÖ **Mix prompt types** - combine different categories for richer results
- ‚úÖ **Use enhancement prompts** strategically to improve overall quality

#### **Template Selection Guide**
- **Sequential**: Simple combinations, tutorials, step-by-step processes
- **Sections**: Reports, analyses, structured content
- **Layered**: Complex reasoning, context-heavy tasks
- **Custom**: Specialized formatting, integration with external systems

#### **Optimization Strategies**
- üéØ **Preview frequently** to catch issues early
- üéØ **Test with smaller combinations** first
- üéØ **Use meaningful names** for easy identification later
- üéØ **Leverage tags** to organize and find combined prompts

### üö® Troubleshooting

#### **Common Issues**

**"No prompts selected" Error:**
- Make sure you've dragged at least 2 prompts to the Selected area
- Check that prompts are actually visible in the Selected section

**"Combined prompt too long" Warning:**
- Remove some prompts or choose shorter ones
- Use more concise source prompts
- Consider splitting into multiple smaller combinations

**Preview not updating:**
- Click the "üëÅÔ∏è Refresh Preview" button
- Check that you've selected a valid template
- Ensure selected prompts are properly loaded

**Drag-and-drop not working:**
- Refresh the page and try again
- Use click-to-select as an alternative
- Check browser compatibility (modern browsers recommended)

#### **Performance Tips**
- **Limit simultaneous combinations** to avoid browser slowdown
- **Clear old selections** before starting new combinations
- **Use shorter prompts** for faster preview updates
- **Save frequently** to avoid losing work

### üîó Integration with Other Features

#### **Token Calculator Integration**
- Combined prompts automatically work with the Token Calculator
- Estimate costs for your combined prompts before using them
- Compare token usage across different combination templates

#### **LangWatch Optimization**
- Use combined prompts with LangWatch optimization
- Improve combined prompts with AI-powered suggestions
- Optimize the final result after combination

#### **Translation Feature**
- Combined prompts work with the translation feature
- Translate combined prompts to English for better AI processing
- Maintain formatting across translations

#### **API Access**
- Combined prompts are saved like regular prompts
- Access via API endpoints once saved
- Include in automated workflows and integrations

---

## üîë API Access

### Setting Up API Access

1. **Navigate to Account Settings ‚Üí API Tokens**
2. **Create new token:**
   - Enter descriptive name
   - Set expiration (optional, 30 days recommended)
   - Click "üîë Create Token"
3. **Copy token immediately** - You won't see it again!

### Using the API

**Base URL:** `http://localhost:7860/api`

**Authentication:**
```bash
Authorization: Bearer apm_your_token_here
```

**Common Endpoints:**
```bash
# List all prompts
GET /api/prompts

# Get specific prompt
GET /api/prompts/name/my-prompt-name

# Search prompts
GET /api/search?q=creative

# Get categories
GET /api/categories
```

**Example Usage:**
```bash
curl -H "Authorization: Bearer apm_abc123..." \
     http://localhost:7860/api/prompts
```

**Interactive Documentation:**
- Swagger UI: `http://localhost:7860/api/docs`
- ReDoc: `http://localhost:7860/api/redoc`

---

## ‚öôÔ∏è Configuration

### Environment Setup

Create a `.env` file with your settings:

```env
# Application Mode
MULTITENANT_MODE=true          # Enable multi-tenant mode (default: true)
ENABLE_API=false               # Enable REST API endpoints (default: false)

# Server Configuration  
SERVER_HOST=0.0.0.0           # Server host (default: 0.0.0.0)
SERVER_PORT=7860              # Server port (default: 7860)

# Database Configuration
DB_TYPE=sqlite                # Database type: sqlite or postgres (default: sqlite)
DB_PATH=prompts.db           # SQLite database path (default: prompts.db)
POSTGRES_DSN=postgresql://user:pass@localhost:5432/dbname

# Authentication & Security
SECRET_KEY=your-secure-secret-key    # JWT signing secret (auto-generated if not set)
LOCAL_DEV_MODE=true                 # Enable local development features (default: false)

# SSO/ADFS Integration (optional)
SSO_ENABLED=false
SSO_CLIENT_ID=your-application-id
SSO_CLIENT_SECRET=your-client-secret
SSO_AUTHORITY=https://login.microsoftonline.com/your-tenant-id
SSO_REDIRECT_URI=http://localhost:7860/auth/callback

# Entra ID (Azure AD) Authentication (optional)
ENTRA_ID_ENABLED=false
ENTRA_CLIENT_ID=your-entra-client-id
ENTRA_CLIENT_SECRET=your-entra-client-secret
ENTRA_TENANT_ID=your-azure-tenant-id
ENTRA_REDIRECT_URI=http://localhost:7860/auth/entra-callback
ENTRA_SCOPES=openid email profile User.Read

# Azure AI Services (optional)
AZURE_AI_ENABLED=false
AZURE_AI_ENDPOINT=https://your-azure-ai-endpoint.cognitiveservices.azure.com
AZURE_AI_KEY=your-azure-ai-key
AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com
AZURE_OPENAI_KEY=your-azure-openai-key
AZURE_OPENAI_VERSION=2024-02-15-preview

# Prompt Optimization Services (optional)
PROMPT_OPTIMIZER=langwatch              # Service: langwatch, promptperfect, langsmith, helicone, builtin
LANGWATCH_API_KEY=your-langwatch-api-key
LANGWATCH_PROJECT_ID=ai-prompt-manager
PROMPTPERFECT_API_KEY=your-promptperfect-key
LANGSMITH_API_KEY=your-langsmith-key
LANGSMITH_PROJECT=your-project-name
HELICONE_API_KEY=your-helicone-key

# Development & Debugging
DEBUG=false                   # Enable debug mode (default: false)
```

### Complete Environment Variable Reference

| Variable | Description | Default | Command Line Override |
|----------|-------------|---------|----------------------|
| `MULTITENANT_MODE` | Enable multi-tenant architecture | `true` | `--single-user` / `--multi-tenant` |
| `ENABLE_API` | Enable REST API endpoints | `false` | `--with-api` |
| `SERVER_HOST` | Server bind address | `0.0.0.0` | `--host HOST` |
| `SERVER_PORT` | Server port | `7860` | `--port PORT` |
| `DB_TYPE` | Database type (sqlite/postgres) | `sqlite` | - |
| `DB_PATH` | SQLite database file path | `prompts.db` | - |
| `POSTGRES_DSN` | PostgreSQL connection string | - | - |
| `SECRET_KEY` | JWT signing secret | auto-generated | - |
| `LOCAL_DEV_MODE` | Enable development features | `true` | - |
| `SSO_ENABLED` | Enable SSO authentication | `false` | - |
| `SSO_CLIENT_ID` | SSO application ID | - | - |
| `SSO_CLIENT_SECRET` | SSO client secret | - | - |
| `SSO_AUTHORITY` | SSO authority URL | - | - |
| `PROMPT_OPTIMIZER` | Optimization service to use | `builtin` | - |
| `LANGWATCH_API_KEY` | LangWatch API key | - | - |
| `LANGWATCH_PROJECT_ID` | LangWatch project ID | `ai-prompt-manager` | - |
| `PROMPTPERFECT_API_KEY` | PromptPerfect API key | - | - |
| `LANGSMITH_API_KEY` | LangSmith API key | - | - |
| `HELICONE_API_KEY` | Helicone API key | - | - |
| `ENTRA_ID_ENABLED` | Enable Entra ID authentication | `false` | - |
| `ENTRA_CLIENT_ID` | Entra ID application ID | - | - |
| `ENTRA_CLIENT_SECRET` | Entra ID client secret | - | - |
| `ENTRA_TENANT_ID` | Azure tenant ID | - | - |
| `ENTRA_REDIRECT_URI` | Entra ID callback URL | `/auth/entra-callback` | - |
| `AZURE_AI_ENABLED` | Enable Azure AI services | `false` | - |
| `AZURE_AI_ENDPOINT` | Azure AI Studio endpoint | - | - |
| `AZURE_AI_KEY` | Azure AI Studio key | - | - |
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI endpoint | - | - |
| `AZURE_OPENAI_KEY` | Azure OpenAI key | - | - |
| `AZURE_OPENAI_VERSION` | Azure OpenAI API version | `2024-02-15-preview` | - |
| `DEBUG` | Enable debug logging | `false` | `--debug` |
| `GRADIO_SHARE` | Enable public sharing | `false` | `--share` |

### Database Options

**SQLite (Development):**
- Zero setup required
- File-based storage
- Single-user friendly

**PostgreSQL (Production):**
- Better performance
- Multi-user support
- Enterprise features

### AI Service Integration

Supported AI providers:
- **OpenAI** (GPT-4, GPT-3.5-turbo)
- **Azure OpenAI** (Enterprise OpenAI models)
- **Azure AI Studio** (Phi-3, Mistral, and other Azure models)
- **LM Studio** (Local models)
- **Ollama** (Self-hosted)
- **Llama.cpp** (Local inference)

Configure in the application's AI Service Settings.

---

## üîµ Azure AI & Entra ID Integration

### Overview

AI Prompt Manager provides comprehensive support for Microsoft Azure services, including:
- **Azure OpenAI**: Enterprise-grade OpenAI models with enhanced security and compliance
- **Azure AI Studio**: Access to Phi-3, Mistral, and other Azure-hosted AI models
- **Entra ID**: Modern Azure Active Directory authentication with Microsoft Graph integration

### üîê Entra ID Authentication Setup

Entra ID (formerly Azure Active Directory) provides enterprise-grade authentication with seamless Microsoft Graph API integration.

#### **1. Azure App Registration**

1. **Navigate to Azure Portal** ‚Üí Azure Active Directory ‚Üí App registrations
2. **Create new registration**:
   - Name: `AI Prompt Manager`
   - Supported account types: `Accounts in this organizational directory only`
   - Redirect URI: `http://localhost:7860/auth/entra-callback` (for local dev)

3. **Configure Authentication**:
   - Add redirect URIs for production environments
   - Enable `ID tokens` under Authentication ‚Üí Implicit grant and hybrid flows

4. **API Permissions**:
   - Add `Microsoft Graph` permissions:
     - `openid` (Sign users in)
     - `email` (Read user email)
     - `profile` (Read user profile)
     - `User.Read` (Read user information)

5. **Certificates & secrets**:
   - Create new client secret
   - Copy the secret value (save immediately - you won't see it again)

#### **2. Environment Configuration**

```bash
# Enable Entra ID authentication
ENTRA_ID_ENABLED=true
ENTRA_CLIENT_ID=12345678-1234-1234-1234-123456789012
ENTRA_CLIENT_SECRET=your-client-secret-value
ENTRA_TENANT_ID=your-azure-tenant-id
ENTRA_REDIRECT_URI=http://localhost:7860/auth/entra-callback

# Optional: Customize scopes (default shown)
ENTRA_SCOPES=openid email profile User.Read
```

#### **3. Multi-Tenant Configuration**

For organizations with multiple tenants:

```bash
# Production example
ENTRA_ID_ENABLED=true
ENTRA_CLIENT_ID=your-production-client-id
ENTRA_TENANT_ID=your-production-tenant-id
ENTRA_REDIRECT_URI=https://prompts.yourcompany.com/auth/entra-callback

# Development
ENTRA_REDIRECT_URI=http://localhost:7860/auth/entra-callback
```

### ü§ñ Azure AI Services Setup

#### **Azure OpenAI Configuration**

1. **Create Azure OpenAI resource** in Azure Portal
2. **Deploy models** (e.g., GPT-4, GPT-3.5-turbo)
3. **Get endpoint and keys** from resource overview

```bash
# Azure OpenAI configuration
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_KEY=your-azure-openai-key
AZURE_OPENAI_VERSION=2024-02-15-preview
```

#### **Azure AI Studio Configuration**

1. **Create Azure AI Studio workspace**
2. **Deploy models** (Phi-3, Mistral, etc.)
3. **Configure endpoints and authentication**

```bash
# Azure AI Studio configuration
AZURE_AI_ENABLED=true
AZURE_AI_ENDPOINT=https://your-ai-endpoint.cognitiveservices.azure.com
AZURE_AI_KEY=your-azure-ai-key
```

### üìä Supported Azure Models

#### **Azure OpenAI Models**
- `azure-gpt-4` - GPT-4 with Azure enterprise features
- `azure-gpt-35-turbo` - GPT-3.5 Turbo with Azure security

#### **Azure AI Studio Models**
- `azure-ai-phi-3` - Microsoft Phi-3 small language model
- `azure-ai-mistral` - Mistral models hosted on Azure

### üîß Testing Configuration

```bash
# Test Azure connectivity
python -c "
from auth_manager import AuthManager
auth = AuthManager()

# Test Entra ID configuration
print('Entra ID enabled:', auth.is_entra_id_enabled())
print('Authentication methods:', auth.get_authentication_methods())

# Test Azure AI configuration
print('Azure AI enabled:', auth.is_azure_ai_enabled())
azure_config = auth.get_azure_ai_config()
print('Azure config:', azure_config)

# Validate credentials (requires network access)
valid, message = auth.validate_azure_credentials()
print(f'Azure validation: {valid} - {message}')
"
```

### üåê Production Deployment

#### **Security Considerations**
- Use Azure Key Vault for secret management
- Configure proper RBAC permissions
- Enable Azure Monitor for logging
- Use managed identities where possible

#### **Example Production Configuration**
```bash
# Production environment variables
ENTRA_ID_ENABLED=true
ENTRA_CLIENT_ID=${AZURE_CLIENT_ID}
ENTRA_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
ENTRA_TENANT_ID=${AZURE_TENANT_ID}
ENTRA_REDIRECT_URI=https://prompts.yourcompany.com/auth/entra-callback

AZURE_AI_ENABLED=true
AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
AZURE_OPENAI_KEY=${AZURE_OPENAI_KEY}

# Use PostgreSQL for production
DB_TYPE=postgres
POSTGRES_DSN=${DATABASE_URL}
```

### üîç Troubleshooting

#### **Common Entra ID Issues**

**Authentication fails with "invalid_client":**
- Verify `ENTRA_CLIENT_ID` and `ENTRA_CLIENT_SECRET`
- Check redirect URI matches exactly
- Ensure app registration is not expired

**No email returned from Entra ID:**
- Verify `email` scope is requested
- Check API permissions include `User.Read`
- User might not have email attribute set

#### **Common Azure AI Issues**

**Azure OpenAI "Invalid API key":**
- Check `AZURE_OPENAI_KEY` is correct
- Verify endpoint URL format
- Ensure API version is supported

**Model not found errors:**
- Verify model deployment names
- Check Azure AI Studio model availability
- Confirm endpoint supports requested model

#### **Token Calculator Issues**

**Azure models not showing costs:**
- Azure pricing included for common models
- Custom model pricing can be configured
- Check model name matches supported patterns

### üîÑ Migration from Generic SSO

If migrating from generic SSO to Entra ID:

```bash
# Disable generic SSO
SSO_ENABLED=false

# Enable Entra ID
ENTRA_ID_ENABLED=true
# ... other Entra ID settings

# Existing users will be matched by email
# SSO ID will be updated to Entra ID object ID
```

---

## üè¢ Multi-Tenant Features

### For Organizations

- **Complete Data Isolation** - Each tenant's data is separate
- **User Management** - Add users with different roles
- **Admin Dashboard** - Monitor usage and manage tenants
- **SSO Integration** - Connect with existing authentication

### User Roles

- **Admin**: Full system access, user management
- **User**: Create and manage prompts, API access
- **Readonly**: View prompts only, no modifications

### Default Credentials

For local development:
- **Tenant**: `localhost`
- **Email**: `admin@localhost`
- **Password**: `admin123`

---

## üöÄ Development

### Development Commands

```bash
# Install dependencies
poetry install

# Run application in different modes
python run.py                                # Default: Multi-tenant
python run.py --single-user                  # Single-user mode
python run.py --with-api                     # Multi-tenant + API
python run.py --single-user --with-api       # Single-user + API

# Development options
python run.py --debug                        # Enable debug mode
python run.py --share                        # Enable public sharing
python run.py --port 8080                    # Custom port
python run.py --help                         # Show all options

# Testing
python test_mt_install.py                    # Multi-tenant setup
python test_langwatch_integration.py         # LangWatch features
python test_standalone_api.py                # API integration
```

### Docker Development

```bash
# Build and run
docker build -t ai-prompt-manager .
docker run -p 7860:7860 ai-prompt-manager

# With environment variables
docker run -p 7860:7860 \
  -e MULTITENANT_MODE=false \
  -e ENABLE_API=true \
  ai-prompt-manager

# With PostgreSQL
docker-compose up -d
```

### Architecture

**Core Components:**
- `prompt_manager.py` - Unified web interface (single-user + multi-tenant)
- `prompt_data_manager.py` - Database abstraction with tenant isolation
- `auth_manager.py` - Authentication and user management
- `token_calculator.py` - Token estimation engine
- `langwatch_optimizer.py` - Prompt optimization
- `api_endpoints.py` - REST API implementation
- `api_token_manager.py` - Secure API token management

### Database Schema

**Multi-Tenant Architecture:**
```
tenants
‚îú‚îÄ‚îÄ id (UUID)
‚îú‚îÄ‚îÄ name
‚îú‚îÄ‚îÄ subdomain  
‚îú‚îÄ‚îÄ max_users
‚îú‚îÄ‚îÄ is_active
‚îî‚îÄ‚îÄ created_at

users
‚îú‚îÄ‚îÄ id (UUID)
‚îú‚îÄ‚îÄ tenant_id (FK)
‚îú‚îÄ‚îÄ email (unique per tenant)
‚îú‚îÄ‚îÄ password_hash
‚îú‚îÄ‚îÄ first_name, last_name
‚îú‚îÄ‚îÄ role (admin|user|readonly)
‚îú‚îÄ‚îÄ sso_id (optional)
‚îú‚îÄ‚îÄ is_active
‚îú‚îÄ‚îÄ created_at
‚îî‚îÄ‚îÄ last_login

prompts
‚îú‚îÄ‚îÄ id
‚îú‚îÄ‚îÄ tenant_id (FK) - ensures tenant isolation
‚îú‚îÄ‚îÄ user_id (FK) - tracks ownership
‚îú‚îÄ‚îÄ name (unique per tenant)
‚îú‚îÄ‚îÄ title, content, category, tags
‚îú‚îÄ‚îÄ is_enhancement_prompt
‚îú‚îÄ‚îÄ created_at
‚îî‚îÄ‚îÄ updated_at

config
‚îú‚îÄ‚îÄ id
‚îú‚îÄ‚îÄ tenant_id (FK)
‚îú‚îÄ‚îÄ user_id (FK)
‚îú‚îÄ‚îÄ key, value - stores user/tenant settings
‚îî‚îÄ‚îÄ created_at

api_tokens
‚îú‚îÄ‚îÄ id (UUID)
‚îú‚îÄ‚îÄ user_id (FK)
‚îú‚îÄ‚îÄ tenant_id (FK)
‚îú‚îÄ‚îÄ name
‚îú‚îÄ‚îÄ token_hash
‚îú‚îÄ‚îÄ token_prefix
‚îú‚îÄ‚îÄ expires_at (optional)
‚îú‚îÄ‚îÄ last_used
‚îî‚îÄ‚îÄ created_at
```

### Security Architecture

**Multi-Layer Security:**
- **PBKDF2 Password Hashing**: Secure password storage with salt
- **JWT Session Tokens**: Stateless authentication with expiration
- **Tenant Row-Level Security**: Complete data isolation between organizations
- **Role-Based Access Control**: Granular permission system
- **API Token Management**: Secure programmatic access
- **Session Validation**: Automatic token validation and renewal

**Data Isolation:**
- All database queries include tenant_id filtering
- Users cannot access data outside their tenant
- Admin users can manage their tenant only
- Complete separation of configurations and prompts

---

## üîí Production Deployment

### Security Checklist

- [ ] Change default `SECRET_KEY`
- [ ] Set `LOCAL_DEV_MODE=false`
- [ ] Use PostgreSQL database
- [ ] Configure HTTPS/TLS
- [ ] Set up proper SSO/ADFS
- [ ] Configure firewall rules
- [ ] Implement backup procedures
- [ ] Monitor application logs

### Production Docker

```bash
# Set environment variables
export SECRET_KEY="your-production-secret-key"
export SSO_ENABLED="true"
export MULTITENANT_MODE="true"
export ENABLE_API="true"

# Deploy with published images
docker-compose -f docker-compose.prod.yml up -d

# Single command with all options
docker run -p 7860:7860 \
  -e MULTITENANT_MODE=true \
  -e ENABLE_API=true \
  -e SECRET_KEY="your-production-secret" \
  -e DB_TYPE=postgres \
  -e POSTGRES_DSN="postgresql://user:pass@db:5432/prompts" \
  ghcr.io/makercorn/ai-prompt-manager:latest
```

**Available Images:**
- `ghcr.io/makercorn/ai-prompt-manager:latest` - Latest build
- `ghcr.io/makercorn/ai-prompt-manager:v1.0.0` - Tagged releases

---

## üöÄ Multi-Language Quick Reference

### üåê **Language Codes & Commands**

| Language | Code | Environment | URL Parameter | Native Name |
|----------|------|-------------|---------------|-------------|
| English | `en` | `DEFAULT_LANGUAGE=en` | `?lang=en` | English |
| Spanish | `es` | `DEFAULT_LANGUAGE=es` | `?lang=es` | Espa√±ol |
| French | `fr` | `DEFAULT_LANGUAGE=fr` | `?lang=fr` | Fran√ßais |
| German | `de` | `DEFAULT_LANGUAGE=de` | `?lang=de` | Deutsch |
| Chinese | `zh` | `DEFAULT_LANGUAGE=zh` | `?lang=zh` | ‰∏≠Êñá |
| Japanese | `ja` | `DEFAULT_LANGUAGE=ja` | `?lang=ja` | Êó•Êú¨Ë™û |
| Portuguese | `pt` | `DEFAULT_LANGUAGE=pt` | `?lang=pt` | Portugu√™s |
| Russian | `ru` | `DEFAULT_LANGUAGE=ru` | `?lang=ru` | –†—É—Å—Å–∫–∏–π |
| Arabic | `ar` | `DEFAULT_LANGUAGE=ar` | `?lang=ar` | ÿßŸÑÿπÿ±ÿ®Ÿäÿ© |
| Hindi | `hi` | `DEFAULT_LANGUAGE=hi` | `?lang=hi` | ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä |

### üß© **Prompt Builder Quick Reference**

| Action | Steps | Shortcut |
|--------|-------|----------|
| **Access Builder** | Navigate to üß© Prompt Builder tab | Direct tab access |
| **Add Prompts** | Drag from Available ‚Üí Selected | Click to select |
| **Change Order** | Drag prompts within Selected area | Drag & drop |
| **Remove Prompts** | Drag out of Selected area | Click X button |
| **Preview** | Select template ‚Üí Auto-preview | üëÅÔ∏è Refresh button |
| **Combine** | Click üîó Combine Prompts | Automatic generation |
| **Edit Result** | Click üìù Open in Editor | Direct transfer |

### ‚ö° **Quick Commands**

```bash
# Start with Spanish interface
DEFAULT_LANGUAGE=es python run.py

# Start with Chinese interface  
DEFAULT_LANGUAGE=zh python run.py

# Access with URL parameter
curl "http://localhost:7860/?lang=fr"

# Multi-tenant with French
DEFAULT_LANGUAGE=fr MULTITENANT_MODE=true python run.py

# API with German interface
DEFAULT_LANGUAGE=de ENABLE_API=true python run.py

# Translation service with Spanish UI
DEFAULT_LANGUAGE=es TRANSLATION_SERVICE=openai OPENAI_API_KEY=key python run.py
```

### üåê **Translation Configuration**

```bash
# OpenAI translation (best quality)
TRANSLATION_SERVICE=openai
OPENAI_API_KEY=your_openai_key

# Google Translate
TRANSLATION_SERVICE=google
GOOGLE_TRANSLATE_API_KEY=your_google_key

# LibreTranslate (free)
TRANSLATION_SERVICE=libre
LIBRETRANSLATE_URL=https://libretranslate.de/translate

# Mock for testing (default)
TRANSLATION_SERVICE=mock
```

### üîß **Developer Integration**

```python
# Quick language switching in code
from i18n import i18n, t

# Available languages
langs = i18n.get_available_languages()

# Switch language
i18n.set_language('es')  # Spanish
print(t('app.title'))    # "Gestor de Prompts IA"

# With parameters
print(t('auth.welcome', name='Mar√≠a'))  # "¬°Bienvenido, Mar√≠a!"

# Translation API
from text_translator import text_translator

# Check if translation is needed
if text_translator.is_translation_needed():
    success, translated, error = text_translator.translate_to_english("Hola mundo")
    print(f"Translated: {translated}")
```

---

## üìö Additional Resources

### Testing

**Comprehensive Test Suite:**
```bash
# Install test dependencies
poetry install --with dev

# Core functionality tests
python test_mt_install.py           # Multi-tenant setup and UI creation
python test_standalone_api.py       # API integration
python test_langwatch_integration.py # Prompt optimization features
python test_api_integration.py      # Full API test suite

# Component testing
python -c "
from prompt_data_manager import PromptDataManager
from auth_manager import AuthManager

# Test database initialization  
auth = AuthManager('test.db')
data = PromptDataManager('test.db', tenant_id='test', user_id='test')
print('‚úÖ All components working correctly!')

# Cleanup
import os
os.remove('test.db')
"

# Multi-tenant isolation testing
python -c "
from auth_manager import AuthManager
auth = AuthManager('test_isolation.db')

# Create two tenants
tenant1_id = auth.create_tenant('Company A', 'company-a', 100)[1]
tenant2_id = auth.create_tenant('Company B', 'company-b', 50)[1] 

print('‚úÖ Tenant isolation test passed')
"

# Test different launcher modes
python run.py --help                         # Show all options
MULTITENANT_MODE=false python run.py &       # Start in single-user mode
sleep 2 && pkill -f "python run.py"          # Stop test server
```

**Docker Testing:**
```bash
# Test Docker build
docker build -t ai-prompt-manager-test .
docker run --rm -p 7860:7860 ai-prompt-manager-test

# Test with PostgreSQL
docker-compose -f docker-compose.yml up -d
# Wait for services to start
docker-compose logs ai-prompt-manager
```

### CI/CD Pipeline

- **Automated Testing** - Python tests, Docker builds, integration tests
- **Docker Publishing** - GitHub Container Registry with multi-platform support (amd64, arm64)
- **Release Management** - Comprehensive automated releases with packages and containers
- **Security** - Sigstore/Cosign signing for supply chain security

**üìã Setup Guide:** See [GITHUB_WORKFLOWS_SETUP.md](GITHUB_WORKFLOWS_SETUP.md) for complete workflow configuration instructions.

#### **Release Process**

The project uses automated releases that create both Python packages and Docker images:

**üöÄ Creating a Release:**
```bash
# Using the release script (recommended)
./scripts/create-release.sh

# Manual process
git tag v1.0.0
git push origin v1.0.0

# Or trigger manually via GitHub Actions
# Go to Actions ‚Üí Release ‚Üí Run workflow
```

The release script (`scripts/create-release.sh`) automates:
- ‚úÖ Version validation and updating
- ‚úÖ CHANGELOG.md prompts
- ‚úÖ Git tagging and pushing
- ‚úÖ Automated workflow triggering

**üì¶ Release Artifacts:**
- **Python Packages**: Wheel and source distributions
- **Docker Images**: Multi-platform containers (linux/amd64, linux/arm64)
- **Source Archives**: Complete source with installation scripts
- **Documentation**: Release manifests and installation guides

**üîê Security Features:**
- SHA256 checksums for all packages
- Signed Docker images with Cosign
- Reproducible and auditable builds

**üê≥ Docker Images:**
```bash
# Available tags (repository names are automatically converted to lowercase):
ghcr.io/makercorn/ai-prompt-manager:latest     # Latest stable
ghcr.io/makercorn/ai-prompt-manager:v1.0.0     # Specific version
ghcr.io/makercorn/ai-prompt-manager:stable     # Latest stable (non-prerelease)
```

> **Note**: Docker registry names must be lowercase. The release workflow automatically converts repository names to comply with Docker registry requirements.

### Troubleshooting

**Common Issues and Solutions:**

**üîß Database Connection Issues**
```bash
# SQLite permission errors
chmod 664 prompts.db
chown user:group prompts.db

# PostgreSQL connection errors
psql -h localhost -U username -d dbname  # Test connection
export POSTGRES_DSN="postgresql://user:pass@host:port/db"
```

**üîê Authentication Problems**
```bash
# Reset admin password (emergency)
python -c "
from auth_manager import AuthManager
auth = AuthManager('prompts.db')
auth.create_user('tenant-id', 'admin@localhost', 'newpassword', 'Admin', 'User', 'admin')
"

# Check tenant configuration
python -c "
from auth_manager import AuthManager
auth = AuthManager('prompts.db')
tenants = auth.get_all_tenants()
for t in tenants: print(f'Tenant: {t.name} ({t.subdomain})')
"
```

**üåê Network and Port Issues**
```bash
# Check if port is in use
lsof -i :7860
netstat -tulpn | grep 7860

# Test application startup
python run.py --single-user --debug
```

**üê≥ Docker Issues**
```bash
# Check container logs
docker logs ai-prompt-manager

# Test database connectivity
docker exec -it ai-prompt-manager python -c "
from prompt_data_manager import PromptDataManager
data = PromptDataManager('prompts.db')
print('Database connection successful')
"
```

**üö® Emergency Recovery**
```bash
# Backup database
cp prompts.db prompts.db.backup

# Reset to clean state (CAUTION: Loses all data)
rm prompts.db
python -c "from auth_manager import AuthManager; AuthManager('prompts.db')"
```

### Support

- üìñ **Documentation**: Comprehensive guides and API reference in this README
- üêõ **Issues**: Report bugs and request features via GitHub Issues
- üí¨ **Community**: Join discussions and share prompts
- üîß **Troubleshooting**: See troubleshooting section above for common solutions
- üìã **Testing**: Use provided test scripts to verify functionality

---

## üìÑ License

**Non-Commercial License** - This software is licensed for non-commercial use only.

### Usage Rights
- ‚úÖ **Personal use** - Individual, educational, and research purposes
- ‚úÖ **Non-profit organizations** - For non-commercial activities  
- ‚úÖ **Academic institutions** - Research and educational use
- ‚ùå **Commercial use** - Business operations, revenue generation, or profit
- ‚ùå **Selling or licensing** - Without explicit commercial license agreement

### Commercial Licensing
For commercial use, please contact the copyright holder to obtain a separate commercial license agreement.

See the [LICENSE](LICENSE) file for complete details.

---

**üîê Secure ‚Ä¢ üßÆ Cost-Aware ‚Ä¢ üöÄ Optimized ‚Ä¢ ü§ñ AI-Powered ‚Ä¢ üß© Builder-Enhanced ‚Ä¢ üîå API-Ready**
