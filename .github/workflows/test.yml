name: Test and Validation

on:
  workflow_run:
    workflows: ["Build and Publish Package"]
    types:
      - completed
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  test-python:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'pull_request' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Update lock file
        run: poetry lock

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Test unified launcher
        run: |
          # CRITICAL: Test launcher help and basic functionality using Poetry environment
          # This ensures dependencies are properly resolved (avoids "Create New Prompt" errors)
          poetry run python run.py --help
          echo "✅ Launcher help command works (using Poetry environment)"
          
          # Test configuration parsing
          poetry run python -c "
          import sys
          import os
          sys.path.insert(0, '.')
          from run import get_configuration, parse_arguments
          
          # Test environment variable configuration
          os.environ['MULTITENANT_MODE'] = 'false'
          os.environ['ENABLE_API'] = 'true'
          
          class MockArgs:
              single_user = False
              multi_tenant = False
              with_api = False
              host = None
              port = None
              debug = False
              share = False
          
          config = get_configuration(MockArgs())
          assert config['multitenant_mode'] == False
          assert config['enable_api'] == True
          print('✅ Configuration parsing works correctly')
          "

      - name: Run comprehensive unit tests
        run: |
          echo "🧪 Running comprehensive unit test suite..."
          
          # Run all unit tests with verbose output and coverage
          echo "📋 Running unit tests with detailed output..."
          poetry run pytest tests/unit/ -v --tb=short --durations=10
          
          # Count total tests
          UNIT_TEST_COUNT=$(poetry run pytest tests/unit/ --collect-only -q | grep -E "^<|::test" | wc -l)
          echo "📊 Total unit tests found: $UNIT_TEST_COUNT"
          
          echo "✅ Unit test suite completed successfully"

      - name: Run comprehensive integration tests
        run: |
          echo "🧪 Running comprehensive integration test suite..."
          echo "⚠️  CRITICAL: All tests use 'poetry run' to ensure dependency resolution"
          
          # Run all integration tests systematically
          echo "📋 Integration Tests Summary:"
          
          # Test 1: FastAPI Web UI Integration (Primary)
          echo "🌐 Testing FastAPI web UI integration..."
          poetry run python tests/integration/test_web_interface_integration.py
          echo "✅ FastAPI web UI integration test completed"
          
          # Test 2: Web UI Functionality
          echo "🖥️ Testing web UI functionality..."
          poetry run python tests/integration/test_web_ui_integration.py
          echo "✅ Web UI functionality test completed"
          
          # Test 3: Multi-tenant Installation
          echo "🏢 Testing multi-tenant installation..."
          poetry run python tests/integration/test_mt_install.py
          echo "✅ Multi-tenant installation test completed"
          
          # Test 4: LangWatch Integration
          echo "🤖 Testing LangWatch integration..."
          poetry run python tests/integration/test_langwatch_integration.py
          echo "✅ LangWatch integration test completed"
          
          # Test 5: New Architecture Integration
          echo "🏗️ Testing new architecture integration..."
          poetry run python tests/integration/test_new_architecture_integration.py
          echo "✅ New architecture integration test completed"
          
          # Test 6: API Integration (comprehensive)
          echo "🔌 Testing comprehensive API integration..."
          poetry run python tests/integration/test_api_integration.py
          echo "✅ API integration test completed"
          
          # Test 5: Language System Integration
          echo "🌐 Testing language system integration..."
          poetry run python tests/integration/test_language_system_integration.py
          echo "✅ Language system integration test completed"
          
          # Test 6: Azure Integration (if configured)
          echo "☁️ Testing Azure integration..."
          poetry run python tests/integration/test_azure_integration.py || echo "⚠️ Azure integration test skipped (likely due to missing credentials)"
          
          echo "✅ All integration tests completed"

      - name: Test new architecture components
        run: |
          echo "🧪 Testing new architecture components..."
          echo "📝 NOTE: Testing repository fixes and hybrid architecture support"
          
          # Test the new prompt architecture with repository fixes
          poetry run python tests/integration/test_new_prompt_architecture.py
          
          # Test repository save functionality specifically
          poetry run python -c "
          import sys
          import tempfile
          sys.path.insert(0, 'src')
          
          from src.core.config.settings import DatabaseConfig, DatabaseType
          from src.core.base.database_manager import DatabaseManager
          from src.prompts.services.prompt_service import PromptService
          
          # Test repository save fix
          temp_db = tempfile.NamedTemporaryFile(delete=False, suffix='.db')
          temp_db.close()
          
          try:
              db_config = DatabaseConfig(db_type=DatabaseType.SQLITE, db_path=temp_db.name)
              db_manager = DatabaseManager(db_config)
              prompt_service = PromptService(db_manager)
              
              # Test the fixed repository save functionality
              result = prompt_service.create_prompt(
                  tenant_id='test-tenant',
                  user_id='test-user',
                  name='ci_test_prompt',
                  title='CI Test Prompt',
                  content='Testing repository save fix in CI'
              )
              
              if result.success and result.data and result.data.id:
                  print('✅ Repository save fix verified in CI')
              else:
                  print(f'❌ Repository save test failed: {result.error}')
                  exit(1)
          except Exception as e:
              print(f'❌ Repository test failed with exception: {e}')
              exit(1)
          finally:
              import os
              try:
                  os.unlink(temp_db.name)
              except:
                  pass
          "
          
          # Test configuration system
          poetry run python -c "
          import sys
          import os
          sys.path.insert(0, 'src')
          
          from src.core.config.settings import AppConfig
          
          # Test environment configuration loading
          os.environ['SECRET_KEY'] = 'test-secret-key'
          config = AppConfig.from_env()
          print(f'✅ Configuration loaded: {config.auth.secret_key[:10]}...')
          "
          
          echo "✅ New architecture tests completed"

      - name: Test enhanced API components
        run: |
          echo "🔌 Testing enhanced API components..."
          
          # Test that enhanced API module can be imported and initialized
          poetry run python -c "
          from api_endpoints_enhanced import router
          from fastapi import FastAPI
          
          # Test API router initialization
          app = FastAPI()
          app.include_router(router, prefix='/api')
          
          print('✅ Enhanced API router initialization successful')
          print(f'Router prefix: {router.prefix}')
          print(f'Router tags: {router.tags}')
          
          # Test that all required dependencies can be imported
          from src.core.config.ai_model_config import AIProvider, ModelConfig, OperationType
          from src.core.services.ai_model_manager import get_model_manager
          from src.utils.github_format import GitHubFormatHandler
          
          print('✅ All enhanced API dependencies available')
          "
          
          echo "✅ Enhanced API components test completed"

      - name: Generate comprehensive test report
        run: |
          echo "📊 Comprehensive Test Report"
          echo "================================"
          
          # Count unit tests
          UNIT_TEST_COUNT=$(find tests/unit -name "test_*.py" | wc -l)
          echo "📋 Unit Test Files: $UNIT_TEST_COUNT"
          
          # Count integration tests  
          INTEGRATION_TEST_COUNT=$(find tests/integration -name "test_*.py" | wc -l)
          echo "📋 Integration Test Files: $INTEGRATION_TEST_COUNT"
          
          # Count E2E tests
          E2E_TEST_COUNT=$(find tests/e2e -name "test_*.py" | wc -l)
          echo "📋 E2E Test Files: $E2E_TEST_COUNT"
          
          # Total test files
          TOTAL_TEST_FILES=$((UNIT_TEST_COUNT + INTEGRATION_TEST_COUNT + E2E_TEST_COUNT))
          echo "📋 Total Test Files: $TOTAL_TEST_FILES"
          
          # List all test files for reference
          echo ""
          echo "📁 Unit Test Files:"
          find tests/unit -name "test_*.py" | sort | sed 's/^/  - /'
          
          echo ""
          echo "📁 Integration Test Files:"  
          find tests/integration -name "test_*.py" | sort | sed 's/^/  - /'
          
          echo ""
          echo "📁 E2E Test Files:"
          find tests/e2e -name "test_*.py" | sort | sed 's/^/  - /'
          
          echo ""
          echo "✅ All tests completed successfully!"
          echo "🎯 Test Coverage: Comprehensive unit, integration, and E2E testing"
          echo "🚀 Ready for deployment!"

  e2e-tests:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'pull_request' }}
    needs: test-python
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies including E2E
        run: |
          poetry install --no-interaction --with e2e

      - name: Install Playwright browsers
        run: |
          poetry run playwright install chromium --with-deps

      - name: Set up display for headless testing
        run: |
          export DISPLAY=:99
          sudo Xvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &

      - name: Run E2E tests
        env:
          E2E_HEADLESS: "true"
          E2E_SLOW_MO: "0"
        run: |
          echo "🎭 Running End-to-End Test Suite"
          echo "================================="
          
          # Create test results directory
          mkdir -p e2e-results
          
          # Run E2E tests with detailed output
          echo "🚀 Starting E2E test execution..."
          poetry run pytest tests/e2e/ -v \
            --tb=short \
            --durations=10 \
            --html=e2e-results/report.html \
            --self-contained-html \
            -m "e2e" \
            --maxfail=5 \
            --timeout=300
          
          echo "✅ E2E test suite completed successfully"

      - name: Generate E2E test report
        if: always()
        run: |
          echo "📊 E2E Test Report Summary"
          echo "=========================="
          
          # Count E2E test files
          E2E_TEST_COUNT=$(find tests/e2e -name "test_*.py" | wc -l)
          echo "📋 E2E Test Files: $E2E_TEST_COUNT"
          
          # List E2E test files
          echo ""
          echo "📁 E2E Test Files:"
          find tests/e2e -name "test_*.py" | sort | sed 's/^/  - /'
          
          echo ""
          echo "🎯 E2E Test Categories:"
          echo "  - Authentication Flow Tests"
          echo "  - Prompt Management Workflow Tests"
          echo "  - API Workflow Tests"
          echo "  - Deployment Scenario Tests"
          
          echo ""
          echo "✅ E2E testing completed"

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: e2e-results/
          retention-days: 7

  lint-and-format:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'pull_request' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Poetry
        uses: snok/install-poetry@v1

      - name: Install dependencies
        run: poetry install --no-interaction

      - name: Check Python syntax
        run: |
          # Check legacy Python files
          poetry run python -m py_compile *.py
          echo "✅ Legacy Python syntax check passed"
          
          # Check new architecture Python files
          find src -name "*.py" -exec poetry run python -m py_compile {} \;
          echo "✅ New architecture Python syntax check passed"

      - name: Check imports
        run: |
          poetry run python -c "
          import prompt_data_manager
          import auth_manager
          import api_token_manager
          import api_endpoints_enhanced
          import langwatch_optimizer
          from run import main
          print('✅ All core imports successful')
          "
          
          # Test new architecture imports
          poetry run python -c "
          import sys
          import os
          sys.path.insert(0, 'src')
          
          # Test new architecture components
          from src.core.config.settings import AppConfig
          from src.core.base.database_manager import DatabaseManager
          from src.prompts.models.prompt import Prompt
          from src.prompts.repositories.prompt_repository import PromptRepository
          from src.prompts.services.prompt_service import PromptService
          from src.auth.models.user import User
          from src.auth.models.tenant import Tenant
          print('✅ All new architecture imports successful')
          "